<!doctype html><html><head><title>Adv. PyTorch: Modifying the Last Layer</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href=/google-fonts/Mulish/mulish.css><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu577c375f84fd7495871e597685ecc2ca_406533_42x0_resize_box_3.png><meta property="og:title" content="Adv. PyTorch: Modifying the Last Layer"><meta property="og:description" content="Modifying the last layer of a pre-trained network for transfer learning in PyTorch."><meta property="og:type" content="article"><meta property="og:url" content="https://mrnabati.github.io/posts/003_adv_pytorch_modifying_the_last_layer/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-06-21T16:42:11-04:00"><meta property="article:modified_time" content="2020-06-21T16:42:11-04:00"><meta name=description content="Modifying the last layer of a pre-trained network for transfer learning in PyTorch."><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-129495160-1","auto"),ga("send","pageview"))</script></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/><img src=/images/site/main-logo_hu577c375f84fd7495871e597685ecc2ca_406533_42x0_resize_box_3.png alt=Logo>
Ramin's Homepage</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme"></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20 alt="Light Theme"></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme"></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20 alt="System Theme"></a></div></li></ul></div></div><img src=/images/site/main-logo_hu577c375f84fd7495871e597685ecc2ca_406533_42x0_resize_box_3.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu577c375f84fd7495871e597685ecc2ca_406533_42x0_resize_box_3.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts/ data-filter=all>Posts</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/posts/projects/>Projects</a><ul><li><a href=/posts/projects/00_fmow/ title=fMoW>fMoW</a></li><li><a href=/posts/projects/01_spacenet/ title=SpaceNet3>SpaceNet3</a></li><li><a href=/posts/projects/02_ecocar3/ title=EcoCAR3>EcoCAR3</a></li><li><a href=/posts/projects/03_ecocarmc/ title="EcoCAR Mobility Challenge">EcoCAR Mobility Challenge</a></li><li><a href=/posts/projects/04_rrpn/ title=RRPN>RRPN</a></li><li><a href=/posts/projects/05_radar_camera_fusion/ title=RCSF>RCSF</a></li><li><a href=/posts/projects/06_centerfusion/ title=CenterFusion>CenterFusion</a></li></ul></li><li><a href=https://medium.com/@ramin.nabati/installing-an-nvme-ssd-drive-on-nvidia-jetson-xavier-37183c948978 title="NVMe SSD on Nvidia Jetson Xavier">NVMe SSD on Nvidia Jetson Xavier</a></li><li><a href=https://medium.com/@ramin.nabati/enabling-can-on-nvidia-jetson-xavier-developer-kit-aaaa3c4d99c9 title="Enable CAN on Nvidia Jetson Xavier">Enable CAN on Nvidia Jetson Xavier</a></li><li><a href=/posts/002_adv_pytorch_freezing_layers/ title="Pytorch: Freezing Layers">Pytorch: Freezing Layers</a></li><li><a class=active href=/posts/003_adv_pytorch_modifying_the_last_layer/ title="Pytorch: Modifying Layers">Pytorch: Modifying Layers</a></li><li><a href=/posts/004_adv_pytorch_integrating_pytorch_cpp_frontend_in_visual_studio_on_windows/ title="Pytorch: C++ API">Pytorch: C++ API</a></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/posts/003_adv_pytorch_modifying_the_last_layer/images/featured.png)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/ramin_hu577c375f84fd7495871e597685ecc2ca_406533_120x120_fit_box_3.png alt="Author Image"><h5 class=author-name>Ramin Nabati</h5><p>Sunday, June 21, 2020</p></div><div class=title><h1>Adv. PyTorch: Modifying the Last Layer</h1></div><div class=taxonomy-terms><ul style=padding-left:0></ul></div><div class=post-content id=post-content><p>All the pre-trained models provided in the <code>torchvision</code> package in PyTorch are
trained on the <a href=http://www.image-net.org/ target=_blank rel=noopener>ImageNet</a> dataset and can be used out
of the box on this dataset. But often times you want to use these models on
other available image datasets or even your own custom dataset. This usually
requires modifying and fine-tuning the model to work with the new dataset.
Changing the output dimension of the last layer in the model is usually among
the first changes you need to make, and that&rsquo;s the focus of this post.</p><p>Let&rsquo;s start with loading a pre-trained model from the <code>torchvision</code> package. We
use the <a href=https://arxiv.org/abs/1409.1556 target=_blank rel=noopener>VGG16</a> model, pretrained on the
ImageNet dataset with 1000 object categories. Let&rsquo;s take a look at the modules
on this model:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torchvision.models <span style=color:#66d9ef>as</span> models
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>vgg16 <span style=color:#f92672>=</span> models<span style=color:#f92672>.</span>vgg16(pretrained<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>print(vgg16<span style=color:#f92672>.</span>_modules<span style=color:#f92672>.</span>keys())
</span></span></code></pre></div><pre tabindex=0><code>odict_keys([&#39;features&#39;, &#39;avgpool&#39;, &#39;classifier&#39;])
</code></pre><p>We are only interested in the last layer, so let&rsquo;s print the layers in the
&lsquo;classifier&rsquo; module:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(vgg16<span style=color:#f92672>.</span>_modules[<span style=color:#e6db74>&#39;classifier&#39;</span>])
</span></span></code></pre></div><pre tabindex=0><code>Sequential(
  (0): Linear(in_features=25088, out_features=4096, bias=True)
  (1): ReLU(inplace=True)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=4096, out_features=4096, bias=True)
  (4): ReLU(inplace=True)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=4096, out_features=1000, bias=True)
)
</code></pre><p>As expected, the output dimension for the last layer is 1000. Let&rsquo;s assume we
are going to use this model on the <a href=http://cocodataset.org/#home target=_blank rel=noopener>COCO dataset</a>
with 80 object categories. To change the output dimension of the model to 80,
we simply replace the last sub-layer with a new Linear layer. The Linear layer
takes two required arguments: <code>in_features</code> and <code>out_features</code>. The <code>in_features</code>
is going to be the same as before, and <code>out_features</code> is goint to be 80:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>in_features <span style=color:#f92672>=</span> vgg16<span style=color:#f92672>.</span>_modules[<span style=color:#e6db74>&#39;classifier&#39;</span>][<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]<span style=color:#f92672>.</span>in_features
</span></span><span style=display:flex><span>out_features <span style=color:#f92672>=</span> <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>vgg16<span style=color:#f92672>.</span>_modules[<span style=color:#e6db74>&#39;classifier&#39;</span>][<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(in_features, out_features, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>print(vgg16<span style=color:#f92672>.</span>_modules[<span style=color:#e6db74>&#39;classifier&#39;</span>])
</span></span></code></pre></div><pre tabindex=0><code>Sequential(
  (0): Linear(in_features=25088, out_features=4096, bias=True)
  (1): ReLU(inplace=True)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=4096, out_features=4096, bias=True)
  (4): ReLU(inplace=True)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=4096, out_features=80, bias=True)
)
</code></pre><p>That&rsquo;s it! The output dimension is now 80. You need to keep in mind that by
replacing the last layer we removed any learned parameter in this layer. You
need to finetune the model on the new dataset at this point to learn the
parameters again.</p><hr></div><div class="row pl-3 pr-3"><div class="col-md-6 share-buttons"><strong>Share on:</strong>
<a class="btn btn-sm facebook-btn" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fmrnabati.github.io%2fposts%2f003_adv_pytorch_modifying_the_last_layer%2f" target=_blank><i class="fab fa-facebook"></i></a>
<a class="btn btn-sm twitter-btn" href="https://twitter.com/share?url=https%3a%2f%2fmrnabati.github.io%2fposts%2f003_adv_pytorch_modifying_the_last_layer%2f&text=Adv.%20PyTorch%3a%20Modifying%20the%20Last%20Layer&via=Ramin%27s%20Homepage" target=_blank><i class="fab fa-twitter"></i></a>
<a class="btn btn-sm reddit-btn" href="https://reddit.com/submit?url=https%3a%2f%2fmrnabati.github.io%2fposts%2f003_adv_pytorch_modifying_the_last_layer%2f&title=Adv.%20PyTorch%3a%20Modifying%20the%20Last%20Layer" target=_blank><i class="fab fa-reddit"></i></a>
<a class="btn btn-sm linkedin-btn" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fmrnabati.github.io%2fposts%2f003_adv_pytorch_modifying_the_last_layer%2f&title=Adv.%20PyTorch%3a%20Modifying%20the%20Last%20Layer" target=_blank><i class="fab fa-linkedin"></i></a>
<a class="btn btn-sm whatsapp-btn" href="https://api.whatsapp.com/send?text=Adv.%20PyTorch%3a%20Modifying%20the%20Last%20Layer https%3a%2f%2fmrnabati.github.io%2fposts%2f003_adv_pytorch_modifying_the_last_layer%2f" target=_blank><i class="fab fa-whatsapp"></i></a>
<a class="btn btn-sm email-btn" href="mailto:?subject=Adv.%20PyTorch%3a%20Modifying%20the%20Last%20Layer&body=https%3a%2f%2fmrnabati.github.io%2fposts%2f003_adv_pytorch_modifying_the_last_layer%2f" target=_blank><i class="fas fa-envelope-open-text"></i></a></div><div class="col-md-6 btn-improve-page"><a href=https:/github.com/mrnabati/mrnabati.github.io/edit/main/content/posts/003_adv_pytorch_modifying_the_last_layer/index.md title="Improve this page" target=_blank rel=noopener><i class="fas fa-code-branch"></i>
Improve this page</a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/posts/002_adv_pytorch_freezing_layers/ title="Adv. PyTorch: Freezing Layers" class="btn btn-outline-info"><div><i class="fas fa-chevron-circle-left"></i> Prev</div><div class=next-prev-text>Adv. PyTorch: Freezing Layers</div></a></div><div class="col-md-6 next-article"><a href=/posts/004_adv_pytorch_integrating_pytorch_cpp_frontend_in_visual_studio_on_windows/ title="Adv. PyTorch: Configuring MS Visual Studio for Using PyToch C++ API in Windows" class="btn btn-outline-info"><div>Next <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>Adv. PyTorch: Configuring MS Visual Studio for Using PyToch C++ API in Windows</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">Table of Contents</h5><hr><div class=toc><nav id=TableOfContents></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://mrnabati.github.io/#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://mrnabati.github.io/#experiences>Experiences</a></li><li class=nav-item><a class=smooth-scroll href=https://mrnabati.github.io/#education>Education</a></li><li class=nav-item><a class=smooth-scroll href=https://mrnabati.github.io/#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=https://mrnabati.github.io/#publications>Publications</a></li><li class=nav-item><a class=smooth-scroll href=https://mrnabati.github.io/#recent-posts>Recent Posts</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=https://github.com/mrnabati target=_blank rel=noopener><span><i class="fab fa-github"></i></span> <span>mrnabati</span></a></li><li><a href=https://www.linkedin.com/in/ramin-nabati target=_blank rel=noopener><span><i class="fab fa-linkedin"></i></span> <span>Ramin Nabati</span></a></li></ul></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hugo-toha/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_3.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2022 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script>
<script type=text/javascript src=/js/popper.min.js></script>
<script type=text/javascript src=/js/bootstrap.min.js></script>
<script type=text/javascript src=/js/navbar.js></script>
<script type=text/javascript src=/js/plyr.js></script>
<script type=text/javascript src=/js/main.js></script>
<script type=text/javascript src=/js/darkreader.js></script>
<script type=text/javascript src=/js/darkmode-darkreader.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script>
<script src=/js/single.js></script>
<script>hljs.initHighlightingOnLoad()</script><link rel=stylesheet href=/katex/katex.min.css><script type=text/javascript defer src=/katex/katex.min.js></script>
<script type=text/javascript defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)>renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})</script><script src=/js/mermaid-8.14.0.min.js></script>
<script>mermaid.initialize({startOnLoad:!0})</script></body></html>